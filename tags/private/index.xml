<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tags/Private on Theoretically Josh</title>
    <link>//localhost:1313/tags/private/</link>
    <description>Recent content in Tags/Private on Theoretically Josh</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 07:15:05 -0700</lastBuildDate>
    <atom:link href="//localhost:1313/tags/private/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Take Control of Your Data: Run Your Own Private ChatGPT</title>
      <link>//localhost:1313/post/private-ai/</link>
      <pubDate>Fri, 08 Aug 2025 07:15:05 -0700</pubDate>
      <guid>//localhost:1313/post/private-ai/</guid>
      <description>&lt;p&gt;AI is everywhere. Companies are racing to add it to everything they can, whether you want it there or not. So, this brings up a lot a questions about how secure our private data really is. Are they using your information to train their AI? Are they selling it? How secure it is? We have already seen case where peoples AI conversations are appearing in Google searches. You might be inclined to just not use or disable AI features, but you may start to fall behind the people who do use these features.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
